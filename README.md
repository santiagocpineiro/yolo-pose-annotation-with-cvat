# YOLO Object and Pose Detection Project

This repository contains scripts and configuration files for object and pose detection using YOLO (You Only Look Once). The project aims to provide a streamlined and efficient way for converting annotations from CVAT format to YOLO format, facilitating the training and utilization of YOLO models for object and pose recognition tasks. It supports multiclassing and visibility.

## Description

The project includes the following key components:

- `annotation_converter.py`: A Python script for processing XML annotations and converting them into YOLO's required format.
- `class_configuration.json`: A JSON file containing the configuration for detection classes, including class IDs and the number of keypoints for pose detection.
- `config.yaml`: An example YAML configuration file for training a YOLO model.
- `annotation.xml`: An example of 2 annotated images in cvat format.
- `out/`: A directory containing example YOLO format annotations generated by the script `annotation_converter.py`.


These components work together to support the training and deployment of YOLO models for various computer vision tasks.

## Requirements

To run the scripts in this repository, you will need:

- Python 3.x


This will process the annotation data and prepare it for YOLO model training.

## Annotation Process

We have documented the image annotation process using cvat.ai extensively in our [Project Wiki](https://github.com/santiagocpineiro/yolo-pose-annotation-with-cvat/wiki).

